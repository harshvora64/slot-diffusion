{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8344426,"sourceType":"datasetVersion","datasetId":4956610},{"sourceId":8347590,"sourceType":"datasetVersion","datasetId":4808627}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch\nimport numpy as np\nimport torch.optim as optim\nimport os\nimport h5py\nimport matplotlib.pyplot as plt\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_epochs = 1000\nfrom sklearn.cluster import KMeans\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics.cluster import adjusted_rand_score\ndir = '/kaggle/input/a2data/'\nout_dir = '/kaggle/working/'\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2024-05-07T15:02:43.528180Z","iopub.execute_input":"2024-05-07T15:02:43.528597Z","iopub.status.idle":"2024-05-07T15:02:43.535239Z","shell.execute_reply.started":"2024-05-07T15:02:43.528564Z","shell.execute_reply":"2024-05-07T15:02:43.534362Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"class HDF5Dataset(Dataset):\n    def __init__(self, hdf5_file):\n        self.hdf5_file = hdf5_file\n        \n        # Open HDF5 file\n        self.hdf5_handle = h5py.File(hdf5_file, 'r')\n        self.data = self.hdf5_handle['images']\n        self.images = [torch.tensor(self.data[i], dtype=torch.float32) / 255 for i in range(len(self.data))]\n        self.masks = self.hdf5_handle['masks']\n        self.masks = [torch.tensor(self.masks[i], dtype=torch.uint8) for i in range(len(self.masks))]\n        \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        return self.images[idx], self.masks[idx]","metadata":{"execution":{"iopub.status.busy":"2024-05-07T14:32:36.676972Z","iopub.execute_input":"2024-05-07T14:32:36.677883Z","iopub.status.idle":"2024-05-07T14:32:36.685208Z","shell.execute_reply.started":"2024-05-07T14:32:36.677849Z","shell.execute_reply":"2024-05-07T14:32:36.684180Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# train_dataset = HDF5Dataset(dir + 'train_dataset.h5')\n# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataset = HDF5Dataset(dir + 'val_dataset.h5')\nval_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T14:59:02.454542Z","iopub.execute_input":"2024-05-07T14:59:02.455411Z","iopub.status.idle":"2024-05-07T14:59:04.131623Z","shell.execute_reply.started":"2024-05-07T14:59:02.455367Z","shell.execute_reply":"2024-05-07T14:59:04.130721Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"for i, (imgs, masks) in enumerate(val_loader):\n    print(masks.shape)\n    plt.imshow(masks[0])\n    break","metadata":{"execution":{"iopub.status.busy":"2024-05-07T14:59:05.229069Z","iopub.execute_input":"2024-05-07T14:59:05.229478Z","iopub.status.idle":"2024-05-07T14:59:05.504859Z","shell.execute_reply.started":"2024-05-07T14:59:05.229447Z","shell.execute_reply":"2024-05-07T14:59:05.503850Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"torch.Size([1, 128, 128])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAakAAAGhCAYAAADbf0s2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7SUlEQVR4nO3df3hU1Z0/8Pe5987c+ZWZyQ8yk0ACQaigUrVEMOK31TVPsVp/rLRdXXZLravbClZkW5Ft0W2rxbr7tK7W6tpn19pvtbbuKv54Ki6NCvXbCAhiRZEfghAImQSSzCSZ3/ee7x/BKaOJkmQmc2fyfj3PPG3uvXPncyDOm3vuuecIKaUEERGRBSmFLoCIiGg4DCkiIrIshhQREVkWQ4qIiCyLIUVERJbFkCIiIstiSBERkWUxpIiIyLIYUkREZFkMKSIisqyChdQDDzyAadOmweFwYP78+di8eXOhSiEiIosqSEj99re/xYoVK3DHHXdg27ZtOPPMM7Fw4UJ0dnYWohwiIrIoUYgJZufPn49zzjkHP/vZzwAApmmirq4ON910E2677bZPfL9pmmhvb0dZWRmEEPkul4iIckxKib6+PtTW1kJRhr9e0saxJgBAMpnE1q1bsWrVqsw2RVHQ3NyM1tbWId+TSCSQSCQyPx8+fBinnXZa3mslIqL8amtrw5QpU4bdP+4hdfToURiGgUAgkLU9EAjg3XffHfI9a9aswfe///2PbD8fl0CDLS91EhFR/qSRwqv4PcrKyj72uHEPqdFYtWoVVqxYkfk5Eomgrq4OGmzQBEOKiKjoHL/R9Em3bMY9pKqqqqCqKkKhUNb2UCiEYDA45Ht0XYeu6+NRHhERWci4j+6z2+2YO3cuWlpaMttM00RLSwuamprGuxwiIrKwgnT3rVixAkuWLEFjYyPmzZuHe++9FwMDA7j22msLUQ4REVlUQULqb/7mb9DV1YXbb78dHR0dOOuss7Bu3bqPDKYgIqKJrSDPSY1VJBKBz+fDBbiCAyeIiIpQWqbwCp5BOByG1+sd9jjO3UdERJbFkCIiIstiSBERkWUxpIiIyLIYUkREZFkMKSIisiyGFBERWRZDioiILIshRURElsWQIiIiy2JIERGRZTGkiIjIshhSRERkWQwpIiKyLIYUERFZFkOKiIgsiyFFRESWxZAiIiLLYkgREZFlMaSIiMiyGFJERGRZDCkiIrIshhQREVkWQ4qIiCyLIUVERJbFkCIiIstiSBERkWUxpIiIyLIYUkREZFkMKSIisiyGFBERWRZDioiILIshRURElsWQIiIiy2JIERGRZTGkiIjIshhSRERkWQwpIiKyLIYUERFZFkOKiIgsiyFFRESWxZAiIiLLYkgREZFlMaSIiMiyGFJERGRZDCkiIrIshhQREVlWzkNqzZo1OOecc1BWVobq6mpceeWV2LVrV9Yx8XgcS5cuRWVlJTweDxYtWoRQKJTrUoiIqMjlPKQ2bNiApUuX4rXXXsP69euRSqXw+c9/HgMDA5ljbrnlFjz33HN48sknsWHDBrS3t+Oqq67KdSlERFTkhJRS5vMDurq6UF1djQ0bNuCzn/0swuEwJk2ahMcffxxf+tKXAADvvvsuZs+ejdbWVpx77rmfeM5IJAKfz4cLcAU0Yctn+URElAdpmcIreAbhcBher3fY4/J+TyocDgMAKioqAABbt25FKpVCc3Nz5phZs2ahvr4era2tQ54jkUggEolkvYiIqPTlNaRM08Ty5cuxYMECnHHGGQCAjo4O2O12+P3+rGMDgQA6OjqGPM+aNWvg8/kyr7q6unyWTUREFpHXkFq6dCl27NiBJ554YkznWbVqFcLhcObV1taWowqJiMjKtHydeNmyZXj++eexceNGTJkyJbM9GAwimUyit7c362oqFAohGAwOeS5d16Hrer5KJSIii8r5lZSUEsuWLcPTTz+Nl156CQ0NDVn7586dC5vNhpaWlsy2Xbt24eDBg2hqasp1OUREVMRyfiW1dOlSPP7443jmmWdQVlaWuc/k8/ngdDrh8/lw3XXXYcWKFaioqIDX68VNN92EpqamkxrZR0REE0fOQ+rBBx8EAFxwwQVZ2x955BF87WtfAwD89Kc/haIoWLRoERKJBBYuXIif//znuS6FiIiKXN6fk8oHPidFRFTcLPOcFBER0WgxpIiIyLIYUkREZFkMKSIisiyGFBERWRZDioiILIshRURElsWQIiIiy2JIERGRZTGkiIjIshhSRERkWQwpIiKyLIYUERFZVt5W5iUisgp10iSYUwMwHBpsnX0wDxyCTCQKXRadBIYUEZW89MxaHFzoRrLSQMV2J6qf64MR6ix0WXQS2N1HRKVNCCR9diQmJ1E+tQexSQLCxnXoigWvpIioKAhdhzJjGuKTy6AkTeh7Q0gfOjzs8eqkSUjPrEXSZ0fPp2xQnbFxrJZyhSFFREVB8bjReW4Fjs1LQ43omLouCO1wOzDM4uLm1AAOLnQjMSUJ1RmF18OQKkYMKSKyHiEAkX03QtjtSJQL+IN9CDtdSHptsGk2SMMY8hRpjx2JSWkEanoz21KGAggAmgooKiDNYUOOrIEhRUTWoqhQT52OgRnlMOwisznlUhCrMeFTTNj0NLpnOSDVs4FhMqavToVSln31pAggFjDRdcFk6OEaePb3Qe58jyP9LIwhRUSWImwaIqdX4HCzhOJO/mW7AjicSdhUEx5XHANnSxw5XRs2pFSbAZ8rO3xUxYS7PoLuSXYYcQ2Vf/Kh+oALBkPKshhSRGQNigph06C4XEiUKdAr+uEf5j6STTWH3fdJ3HoSbj2JWNKGpLccwuWEEhv6XFJKyFQaMIfuUqT8Y0gRUeEJAfXU6YicXoGkR0F4JuCwp/P6kZpqoLfOROgLU6HF64c+JibhfesojD37eO+qQBhSRFR4QsHAjHIcbpawlw9At6fhsOU3pGyqCU9DGP2TNUgphjwm2e2AFq+Avvd9QPJqqhAYUkRUcEIRMHQBxZNEeVl03D7XaU/BaU8Nu78zocGw88HfQuKME0REZFkMKSIisix29xHRuBI2OxSPG9D+8vUjNBUplwKhWGtwglAkUi4BrboKMpGE2T8AmUp+8hspZxhSRDSulGlTcKwpgHjlXwYrSAWI1ppwOIa/P1QITlcSR89yIBo4BXqPxKTXjsLYuafQZU0oDCkiGlepgBddjSZ8U8NZ232KCZtqFqiqobn0JPRZx2B+SsHRI154D3qh7Sx0VRMLQ4qI8kLY7FD8PgiXI2t7X5Ud0mFCz/MQ81xQhISiSkA1AVVCqkMPVaf8YUgRUV6o1VXo/lw9IlOPT+p6XKJcQvf3F64wKioMKSLKC+l1o/t0Ae+ZR7O2u4WEIqw1QIKsiyFFVAJUrxfCWza4xMUIyGQSZm84P7OACwEpBid1LQXCZiI6yYaKU2dkTZEkYgmYXUdhxuMFrK50MaSIipzQNJinTsWxMzww9JG919Vlwrf5MNJth/JTXAlxeePobNLQM3tS1vayA0CgRYO57/3CFFbiGFJExU5VEa92IDwTMBwj60ZLu1R4d7ryVFhp8TgS8Ez/6BXnUX0SJm3hn2G+MKSISoD8oJtvhIPPDB1I1JRBT02HiMZhHD3GBQBHQY6wm5VOHkOKaAJLeSVCjTrUM4IoO2TA9ycT6SMdhS6LKIMhRTSBGQ6JWGCwi1BJq/A5HZ/wDqLxxZDKNyGg6DqEY/g72jKVhhmLc/VPGhG1qhKYVAHTZUesUoUc7XTRAsMuwU5UaAypPBOqCqWyAtJfNmy/tRKNA6EumAMD41wdFS1FhTG9Fp2NZUh7gJQbkLbSGOpNdCKGVL4JBbDbYLjtgDJ0SAkpIVR1nAujYpfy2hELSqTKeBlEpYshNUZC16G4XMMGEDQN0mH/2HNITYHi80K1Zf91yGQK5kCU3YA0LlIeYGDWJOhVZVB7BiDb2vmAKhUcQ2qMlDIPUF0JaRvmSkgISE0ZPsQASLsGo8oHYZZlnzs8AJlMQiYYUpR/iXKJUKMNSsoG/3tu+CL9AEOKCowhNRZCQGgaDKdt+JA6CVIVgKpCIvscImaDUFXe06b8E4CpSyR1CUggcXTwd5uo0PhbeJIyq4nabVnbpcc14vnSTpa026BUlEOUef6y0ZSQ0SjMaDRr/jAiolI02kGrJ+3uu++GEALLly/PbIvH41i6dCkqKyvh8XiwaNEihEKhfJcyJorTAVRXwqydlP3yuwe78/JAOm0wAv6sz5O1VVDK/RxoQUQTQl5DasuWLfiP//gPfPrTn87afsstt+C5557Dk08+iQ0bNqC9vR1XXXVVPksZOSGyXzYNUtcgdTX7laeAAga7AaUt+/NMXQNs2uCoQU7FQkQlLm/dff39/Vi8eDF+8Ytf4M4778xsD4fD+M///E88/vjj+Ku/+isAwCOPPILZs2fjtddew7nnnpuvkk6K0DQoPi+E/UMj8pwOmBa5epFOHWpgEpBOwxyIwuzrK3RJRER5kbfLgKVLl+LSSy9Fc3Nz1vatW7cilUplbZ81axbq6+vR2tqar3JOmrDbgQo/jNrK7FeFB9KW997RT6YImG4dRrAcZrBy8D4Zr6iIqETl5UrqiSeewLZt27Bly5aP7Ovo6IDdboff78/aHggE0NEx9MSWiUQCiRNmZo5EIqMvTojBrrLhqCqgqWMarZdvUhUAjndD2m0Qmg3SMABpluZgCiGguFwQuZpXTkrIWHxw8Anl1vFpwGCzwXTZRz9VE9FxOQ+ptrY23HzzzVi/fj0cjtx8qaxZswbf//73x34iIaD6vBAez/BXHzYNpm4bep/FSAFItxNqbQBIGzAjfSXZ9adWVeHoJTPQPUdC5uDfDkpCILjZhGfdWwyqHFN9XsTnzURkqg0Jv0C6OlnokqjI5Tyktm7dis7OTnzmM5/JbDMMAxs3bsTPfvYzvPjii0gmk+jt7c26mgqFQggGg0Oec9WqVVixYkXm50gkgrq6upEXJxSIsjIY1T5AGf6feLJYes8UAcOjQ7h1iJQBxTBg9veX3tVUhQ9HL0rgqf/zIFxKesynez/lx1LlHzBzoxNgSOWU8HnRebYdRmMfNM1AhTb2vy+a2HIeUhdddBHeeuutrG3XXnstZs2ahZUrV6Kurg42mw0tLS1YtGgRAGDXrl04ePAgmpqahjynruvQ9RGuiy3ER4ZpC00DNBVQlONdZiVAEYMP+5oC0DQIzQZI83j3XxGHlRBQ/X4IjxuJWi/8/gHMtivQhXvMp3aJHqQrUpBTAtAcDshIH4yxdCGXAgkIQ0BJAcIA1DgAYxQznQgB0w54nAmoCie8pbHLeUiVlZXhjDPOyNrmdrtRWVmZ2X7ddddhxYoVqKiogNfrxU033YSmpqacjuxTPB4ofh+gnnDFpCgwXY7iuVIaCUWB9LoH5/9LpWH29Bb1rOqq34+jl89CV5MBmz+OG0/ZBA25uU/oVzRcdfY2rP2nMyG76zD5FQn377dP+BVp7b0C/r0m9LABPRSF2ddf6JKICjPjxE9/+lMoioJFixYhkUhg4cKF+PnPf57Tz1DcLpiVXpj2Ib7YPmYevWIl1cGuP3h0KIk0RCIJFHFICY8bXU0Gfn/xvQiqgEuxQRW5uVfoURz4YeA1rKr+I15PVOCW7uvg+YN9woeUHgb8b3TB3N8GaRiQnNiYLGBcQuqVV17J+tnhcOCBBx7AAw88kNfPlaooyUAa1gdtLdYh6UJAraoCKnxI1Hph88cRVIFy1ZXTjzGkiUNGCntSlXh9YDq0GACz+Lqm1LgBW58ApIBplzDtcmyj6SQg0gZkioMdyDo4dx9ZhuJy4dgXZqCrOQG/fwA3nrIJLiX3Iy0jZhw37f0btL1cD70HqHljoPiuoqQJ+/tdqDGqYLg09M6wIzJdQNqL+D4k0RAYUmQZwunAsTnA2s/+HKfaVGhQc9bFd6I+aWLPzsmY/cj7MEKdg11bxTbIREqkDx2GONwOu9MJj+sM9E2z7rN9RKPFR+1KkBQCQrcPPgCr64BSJF9ehgm9W+D/djfh15E6vJ1KwpC574azAVDKk4ieUQuceSq0YKB4u0ilPD6SExjNmi5KSsAeVuA4qkAPm0CKQ8bJWnglVYo0Baa/DMLlgJJMwTzWUxQP+Zr9A5jS0ocN7efixSqBmksO4n9O/W94RI5mmjjOp9jx7bP/F08G5uJAjw/e5xpQ8bveCbkKrS0sULUjDeeRGNRwDGZ3T6FLIsrCkCpBUhWQHjsAO5RoEqJIhhLLVBLY/BbKtwhoU+vwzuwg4p8y4Pnkt46IS7HjG/7DuN7Xhq1JA1/d+S1U2GwTchVaLQZ49vTCeGc3OJaPrKhkQ0qmUlCiycGlLtTBZS4mpGLsxpIyrw8ip6SBjXE7NvafjrfCtXCGxOgeXLUKU8IeTsHVocHQR/b37eySELEiGzRiMabLxECDBx55GpTwAMwjoQl5VZ4vJRtSZqQfSioNYdMgyn0wNU/pzDJBY9JjxvHtHYuhPVMOR4+Jml1HYcSL94taplOw7T6M2u7yEa9vJgbiMDuP5qmyiUGvjuLwX7mgnuuDb48PgRfSMA8dLnRZJaNkQ0qmkjBSSUAIaE7n8X+ZM6QIiEuJ8AEfZj23F0ZXV/F3c0kJI9QJhDoLXcmE5HPHgOkxAEBPchKqXbm9hzrRlWxIEQ3HIQQ89REcvWQGnMca4N7TDWPPfoAzLBBZDkOKJpxyxYF/O+O/0TL1dOyMBNH22+kItrVz2Q4iC2JI0YRjEyo+70rh867t2OpP4m9rbh5c7JKILIcP8xIRkWUxpIiIyLIYUkREZFkMKSIisiyGFBERWRZH9xFR7kgJkQYSaRWaIqCpJhRRZMugjJApBdKGAikFlLTI65ReExFDiohyRvYPoGpHGr2xcsS8QGJGHNVVkUKXlVfHejyw73XCHgaqDhhApDgmdC4WDCkiyhmjJwz3hnfh3uxA+pQa7Pe4gKpCV5VnR3VMfiUO+85DQCIBgyGVUwwpIsod04ARiQCRCLRKP0TaVeiK8k6kBLRwYnD+RMo5DpwgIiLLYkgREZFlsbuPiGiEUoaCeNKGdFqFFgOEYYBj+vKDIUVENEK9YTdcf3bCf0TC1ZWGCHUXuqSSxZAiIhohM2JDYHMcttfegTRMGOlUoUsqWQwpIsqPVBq2PoGu7jKomgG3Mwndli50VTkhTAElZcKMxwtdSsljSBFRfhztQe0fvYjt1jEQVNE7N4lAsLfQVVGRYUgRUV4YPT1Q/hSBRxFwN56GyAwXECx0VVRsJkRIyVQKIp6G0BTI4y8iGgemAWkCIm2i2Ie/JdMqIv1OGDENjqMqlGiq2JtUFEo/pKSEDEcg0mlA0yD8Xhg+J6CIQldGREUk0ueCZ5MT/r0p2MNRKIc6YRS6qAmg9EMKGLy5GY9DaBpUhw7hdfJfQEQ0IkZMRfmuJOz/uxWQkgE1TiZESBGdKCUN/L+4Da8OfAp/jkyGs1MABr9y8kmJJuHqUBByVgAOA2XlUbjsRTZsWwoIKbkUxzhjSNGE02PGseLtv4XybAUcPSZq3z0GI54odFmlrT2EKS+qSHsd6PmUA8fOB1yBcKGroiLAkKIJJy4let/3Y9Yze2F0dbHbZhwYvWGgNwwFQDnOxrFGW6FLoiLBkCJLkvEEXPvs+Id9V8Frj2W2B/Q+fLl8M+bpI/uSM6SJlpiOZ3s+g339lfC8rwKpZK7LppOgReLw7HeiK1YFs8xA2aR+y3b9JVIaeo96oIQ1uLoU2Hv6eD97nDGkyJLM3jCmPnMM4W316D3hiYG3Gmw4stiHX097ZUTni8kk7tjzZZiPV8PVmcKU9zth9g/ktmg6KWL/YdQ9l4bp1nH0rDL0XOCAq8KaIdU/4ED56zZUv94PJZoE2jmib7wxpMiSZCIB4+1dsL+dvb163hzsvbQKhjShipN/3i0lTYRCfsx+tR3p/Qf4RVNAHyyKCCHgmdSIYwm10CUNy0grcHeYkFvfgWHyt6YQGFIlTioKFI8bKgCk0jCjUch08c6fpoZj6N4+Cc22vx7R++JpDe53dMho7JMPpvEhJRxdMXh2etEdmoRUhQFvsA/OAnT9pQwF3V1e2DptECdkkSsi4AwNANIc95poEEOqxEmbAqPCC+FzQ8SSEB1dkH19hS5r1GRbO2b8WkHq9+Ujel+ZBMpDR2B29+anMBoVZfdB1PVWQjp0dC4oR98F9oKEVDKtwbPTjskvRwa79T6QSgNdx2Bw2HnBTKiQkuYE/EVTBKSuQkKFYgJCLe4pocxoFHhn96iWlGZnjfV80PUnNA3OU+eiJ6XCMBUIIaGI/P/3akoBKQXSaRXuHgmx6wCMIv5HXCmaUCEFaUIORKH0aICiQLp0mI6J9UdAZEXSMOBqj6PsDTf6vQ7Eg2n4ayN5XdrDMBUcDXmhH7ZBGxDwvp8AUtYcwDGRTaxvaClh9oaBvn4Iux0iOAmwuzmPH1GhSQl1xz5MafNCup04clE14lW2vIZU2lDg2mtH/e97oPT2Q4YjMBJ8qNtqJlZIAYODBtJpwJRQDN4MJUBoGqDmf4SZTKUBjhAbltnXB7OvD4rDAT1chb6UimQ6++9FVSRUZfC/25ShQMrR/wMzmVZh6wfEoRDSx7j8u1VNuJAiOpHiciE1bxZ6TtVhqvm7olYTEpVv9UNs21nUoyvHg0yn4d0fQ+L/uZF2uDLbDTsQbUihqjaMWNKG+L4yODsUjPbWlWYAFbuSkJwSy9IYUjShCbcbR5ocOPULe+Cz528p8IP95ejUpyC4w86Q+gQynYa6fQ9q9nyoK77SjwNXVMEICsSidlRvAype3gdpjr5HREZjg4NxyLIYUjQ2igrx4a4yaUIahuVmixY2O4RDhxAnfPH5PEj6JOb42lGl9efts91qEi/7pkDxeQe7F4+ThgGZSDC4PsSMRoEPhYdqStgGqhCN22FGNehhA+mOkOV+zyi3GFI0akLXoU6ugVFZhhNvDagDSaDtyODwYosQmgazcTY6G91I/6UHCYYDcM7qgUvJ7zx+flsUyTlR7P/6dCgn5JE9LBFo7YV8c2deP78UyGgUVW/F0RP3wBcDXO9387GCCSAvIXX48GGsXLkSL7zwAqLRKGbMmIFHHnkEjY2NAAApJe644w784he/QG9vLxYsWIAHH3wQM2fOzEc5lCeKriNRX4HIVB04IaQcPQbKIgODU99Yhaqi+wwXAlcexKm+UGazTRjwanHoSn6HHlfZ+vC3p29B+FQnzBMSvbWjAZFj5fD8WfCK4BOY0Shsre8g8IYOmBJmLM4/swkg5yHV09ODBQsW4MILL8QLL7yASZMmYc+ePSgv/8sMAffccw/uu+8+PProo2hoaMDq1auxcOFCvPPOO3A4HLkuacITxuBCbcIwgFE+0Cw0LaubCgDgdMDQFZh2ZF1JGXYB6bBDcTggDRMynSrYl4nicEB43BBuFxJ+gXpPD2Y6O8e9DhUSVVr/R7oU3y+rRLu/Ev5gIPveSjIFs6+P3YAnkjKzyjZNHDkPqR//+Meoq6vDI488ktnW0NCQ+f9SStx777343ve+hyuuuAIA8Ktf/QqBQABr167F1VdfneuSJjSRMqCEoxCxBGQyBXM0z4EoKtQptUjVlEOeMALOtKtI+D/6K5R2KIidUgkt4IXWG4dysL0wXX9CwDj7VBw5341EuYQyow8B3UJXdwCmuY/h7c/WoG9qA05cA8J9GAi2hGDs2Ve44ogsIOch9eyzz2LhwoX48pe/jA0bNmDy5Mm48cYbcf311wMA9u/fj46ODjQ3N2fe4/P5MH/+fLS2tg4ZUolEAokTvlwjVupGsjiRNoHeyF+eAxnFFY1QVaSrfQjPdME84TdGCgBK9lUUMHifp2+yBiE1uEM2uI86C9P1JxSEZ7hQvfAQmqr2w6Uk4VKtNdx4urML157Zivic7PWxfrfzM0jt9EHZU6DCiCwi5xO57du3L3N/6cUXX8Q3v/lNfOtb38Kjjz4KAOjo6AAABAKBrPcFAoHMvg9bs2YNfD5f5lVXV5ebYg0DStKASBmDXWJFTqRNiISR/UoZgw8vSznigBI2OxS3G4qvDKauwdSQ9ZLqRwMKGNwm1cFjDLsC6XFBKSuD4nAAIv+zeyguF7Qpk6FOr0e8QmCSsx8BWwRlahyqxZasUyHhU2MI2CJZL7uehuRMKES5v5IyTRONjY340Y9+BAA4++yzsWPHDjz00ENYsmTJqM65atUqrFixIvNzJBIZc1DJdAqyJwwRT0Cx2WD6yyA99jGds5CEIaFEYhCR7HseMp0evME84hMKqLUBJOsqYThUJMo1yFH8kybpURD9VBW0unLYjkWhvNcGcyC/iw3K00/B+81liFeb0OsiqHP25PXziCh/ch5SNTU1OO2007K2zZ49G//zP/8DAAgGgwCAUCiEmpqazDGhUAhnnXXWkOfUdR26rue2UCkzMzArDgeEUweKOKRgmhB9A0h3Hs3N1DticImPSIMThg5ADH3V9EkMB9A/WQOkhjJdhbPdAeQ5pAbqXPB/rgOXT34LijBhExyoTFSsct7dt2DBAuzatStr2+7duzF16lQAg4MogsEgWlpaMvsjkQg2bdqEpqamXJdzUqSUEKk0lFhqsIvM4l1/Im1Ciac/8pJpI2eLs4njXU1SOf4aZc+TPB5uUgEMXUB4y6CWl0NxuXLa9ae43dCmT4N6+qnoD6rw6XG4lCQcIm25Lj4iOnk5v5K65ZZbcN555+FHP/oRvvKVr2Dz5s14+OGH8fDDDwMAhBBYvnw57rzzTsycOTMzBL22thZXXnllrss5KTKVhnmsB6J/AIquw6z0QroselVlSigDCaA7DBgnXCFICTkQtfRzI8kyBf2nVUNJVcFxpB/K3oO5m5Jm5lTs/6IfsfoUyqp7MNs79P1NIiouOQ+pc845B08//TRWrVqFH/zgB2hoaMC9996LxYsXZ4659dZbMTAwgBtuuAG9vb04//zzsW7dusI9I2UaMPv6gL7Bf5ELr7swdZwkEUvAONZddM/QpFwCaacKSBVK2g39/dz9+iWqXbA19uAfZmyCIkxePRGViLzMOPHFL34RX/ziF4fdL4TAD37wA/zgBz/Ix8ePjWFAxJNQbB+aj05RYNrVcV17SqTNwdF5J1wdCUMCiWTRrjIsxeDkFIZDgaiqgOp0DE7y2d8/pqtAKQBFyJK5/1TmjKN3uheVsU9D7YlCtrVzIlSakDh334eYyRTQeRSiN7u7T3jcQKV3XFfyVWIp4GgPkDxhyh5pwowninpdIimAWIUG89PVUFISzrY+iF37IbngXMY5kw7i1Ss0vHeRE/qOakz9bwnsfq/QZRGNO4bUh5nG4BDpD41AUwGg3DO+taTSkOHI4FQwJSbtBNJOFcIAbBEnNJUddCea6ezEzFM6YUDgfuNCmF5noUsiKgiGlMWItAmRTA/+bywBk6sHT2iZ6B6Hh6CJrIghZTEinobo6gZicZjJ5ODkrEREExRDymKEYUD2D+R9VgYiomLAkDpJMpmE0heDSJww7FsRkHYNpq6NadSfSJuDV1CpNEQ0Priq7UQhgJRXg23qZGixBGS4D0Zvr6Wf9yKi8cOQOklmLA4cCQEfWipdqSiHrPZBKuow7/xkIjnYxSf7+mEaBmQyv6vEWooAolUakp5KqCkJz3tuiP4ByNQE+jMgomExpE6WacCMf/QKRynzAGMc2yAMOXgPyoLPwQg5+AJGPzWS+ISLItMOJHQBJSXgdNmhcPZvIjqOITVGMh6H2tsPadMgHTaYDtuwXX/CkFCiyeznngCIeBKmxa6epGFA6+1HWZsOQ1eR8KlIlokRz4SuxQeXk1eSwyS5EEiWKUh4cz6NJBGVAIbUGBmRfohYHEJVoVRXQdq9w68DlDYhevtgfrAA4XHmB0usW4mUMNo7YO/pBXQd6uwpSLn1EYeUvd+Ee9cxoKt76ANUBbZPTUHK5RrVUiBEVNoYUmNlGpAJA1IIKKnjiwsOM2WRMM3BJdyL5OFcmUjASCQgbHao8SCEoUMo+MRlO4REZil0JSkHlxDpGWZNJ0WFGg1AMSRMCIiP+fMjoomHIZVDcmAA6jFt+Acv00bRBNSJpGFA64zAZ1Nh6AoSFTYkfGLYoFITgPNYGtqAAVtvfHB29mFPbkI5FoF3vx1SEdA6I0hPpNGNRPSxGFK5IuVg199A7GOOMYtzeLlpwGhrhxbqgs3lgphTj0SZ/fhcUR+lxUy49vZAtoeAVArGx83JJyWMIx1QuwevtIxkqqjnJSSi3GJI5ZJpQJboF6xMJSFTSShSQk0YUI73bH6wKOKJhAmIeAJGX9/JnTudLrplR4hofDCkaERkKg3bkV74TQnToSJabUfSO3zXHxHRWDCkaERkKgnj4CEoh49A8/tg2OuR9NoKXRYRlSiGFI2YTKeBdBqIxaEmTKgJwBxccJfDyIkopxhSNGpmIgH9wDFo/WUwnDYM1OpI+NjvR0S5w5CiUZOJBNIHDkG0CdirKpHy1iPh468UEeUOv1FobEwD0gRkIgk1ZkKLAVrcBLhYIxHlAEOKcsKMRuHY1wX7URdELAkzHCl0SURUAhhSlBODXX9tJ2zg1EZENHYMKcodBhMR5RgHDBMRkWUxpIiIyLIYUkREZFkMKSIisiyGFBERWRZH91FJsIeT6Nvrx8PmAgS9fZhf+T4CNj6rRVTsGFJUEtQ9hzDjiclIeZ040ujHO5fGEahkSBEVO4YUlQTjWDdwrBsaAH/5fPQkXIUuiYhygPekiIjIshhSRERkWQwpIiKyLIYUERFZFkOKiIgsiyFFRESWxZAiIiLLYkgREZFlMaSIiMiyGFJERGRZDCkiIrIshhQREVkWQ4qIiCyLIUVERJbFkCIiIstiSBERkWXlPKQMw8Dq1avR0NAAp9OJU045BT/84Q8hpcwcI6XE7bffjpqaGjidTjQ3N2PPnj25LoWIiIpczkPqxz/+MR588EH87Gc/w86dO/HjH/8Y99xzD+6///7MMffccw/uu+8+PPTQQ9i0aRPcbjcWLlyIeDye63KIiKiI5Xz5+D/96U+44oorcOmllwIApk2bht/85jfYvHkzgMGrqHvvvRff+973cMUVVwAAfvWrXyEQCGDt2rW4+uqrc10SEREVqZxfSZ133nloaWnB7t27AQBvvvkmXn31VXzhC18AAOzfvx8dHR1obm7OvMfn82H+/PlobW0d8pyJRAKRSCTrRUREpS/nV1K33XYbIpEIZs2aBVVVYRgG7rrrLixevBgA0NHRAQAIBAJZ7wsEApl9H7ZmzRp8//vfz3WpRERkcTm/kvrd736Hxx57DI8//ji2bduGRx99FP/2b/+GRx99dNTnXLVqFcLhcObV1taWw4qJiMiqcn4l9Z3vfAe33XZb5t7SnDlzcODAAaxZswZLlixBMBgEAIRCIdTU1GTeFwqFcNZZZw15Tl3Xoet6rkslIiKLy/mVVDQahaJkn1ZVVZimCQBoaGhAMBhES0tLZn8kEsGmTZvQ1NSU63KIiKiI5fxK6rLLLsNdd92F+vp6nH766XjjjTfwk5/8BF//+tcBAEIILF++HHfeeSdmzpyJhoYGrF69GrW1tbjyyitzXQ4RERWxnIfU/fffj9WrV+PGG29EZ2cnamtr8Y//+I+4/fbbM8fceuutGBgYwA033IDe3l6cf/75WLduHRwOR67LISpqBkShSyAqKCFPnAqiSEQiEfh8PlyAK6AJW6HLIYsZ+NJ82P6xA1fVbi90KaO2J1aNV9unI9LvhL7Dhan/HYKx+71Cl0WUM2mZwit4BuFwGF6vd9jjcn4lRURjt6WrHsqzFZj+dhRabxfk4aEfzyAqdQwpIgvqizkQfC8B0fomjEIXQ1RAnAWdiIgsiyFFRESWxZCikiNMIGWoiJp2xKXGEXJERYz3pKjkuNuiaNsYxMPV1XDU9eGL09/GFHtPocsiolFgSFHJEW+/h2lHyiEddhy+tAYHghUMKaIixZCikmNGozCjUUBRoYeDiKeL41m6lBzsokxJFcmkCmEW3SOMRDnHkCKyiJ0DNfjD27NhP2yD5zBgaw9x+DlNeAwpIovY1VuNQIuGypZ9kKkUzEh/oUsiKjiGFJU0JSXRFXPjvfgk+LQYyrUBqLBON1pKquhOu9Fv6DjW78KkHgPpjlChyyKyDIYUlS5pwv9uH0LPBfG//iASs2P40ulvWGoQxd5YNV7YPgeufTY4uyRc+4+yi4/oBAwpKl1SAn/eg+BuHcLlxKHFM9A9022pkDo4UI6qP2mYtHYnZDIJM5EodElElsKQopImU0nIVBIimYQ9LLGrtxqmFKjS+1Fj7y14158pBbSEhNHbOxiqRJSFIUUTgkylUbU9gqMIYouvBgOfieHv5mxGlcbBCURWxpCiicE0IN94F1U7NCh+H953zkD/bJ0hRWRxDCmaOEwDMmFARmPQe4FNXdPwnnNSZrdDS2Gqqztn3YApqeJgogKHon6kTXXIY97rrEIgao75s4hKFUOKJhwZiyHwWhjhnmq02/4y+WzCL/Dn/xPBtbNaoYr0mD+nz3Dg2bc/Df+fdGixoY+Z1G/Cs6MTBu9HEQ2JIUUTjkyngW3vwPtG9iIA6ilTsauhGuapCnIxcXrC1KC/50Dw6b0wuo4Ne5xhctA50XAYUjQxSQnI7HAQsQQcIQXPHp4DmzL2LrhIXIfjKIBEAmAQEY0KQ4roOLO7B3V/qMDArklI52ClNU9awr2vG+bAMH19RPSJGFJEx5nRKLDlLbi25PCcuTsV0YTElXmJiMiyGFJERGRZDCkiIrIshhQREVkWQ4qIiCyLIUVERJbFkCIiIstiSBERkWUxpIiIyLIYUkREZFkMKSIisiyGFBERWRZDioiILIshRURElsWQIiIiy2JIERGRZTGkiIjIshhSRERkWQwpIiKyLIYUERFZFkOKiIgsiyFFRESWxZAiIiLLYkgREZFlMaSIiMiyRhxSGzduxGWXXYba2loIIbB27dqs/VJK3H777aipqYHT6URzczP27NmTdUx3dzcWL14Mr9cLv9+P6667Dv39/WNqCBERlZ4Rh9TAwADOPPNMPPDAA0Puv+eee3DffffhoYcewqZNm+B2u7Fw4ULE4/HMMYsXL8bbb7+N9evX4/nnn8fGjRtxww03jL4VRERUkoSUUo76zULg6aefxpVXXglg8CqqtrYW//RP/4Rvf/vbAIBwOIxAIIBf/vKXuPrqq7Fz506cdtpp2LJlCxobGwEA69atwyWXXIJDhw6htrb2Ez83EonA5/PhAlwBTdhGWz4RERVIWqbwCp5BOByG1+sd9ric3pPav38/Ojo60NzcnNnm8/kwf/58tLa2AgBaW1vh9/szAQUAzc3NUBQFmzZtGvK8iUQCkUgk60VERKUvpyHV0dEBAAgEAlnbA4FAZl9HRweqq6uz9muahoqKiswxH7ZmzRr4fL7Mq66uLpdlExGRRRXF6L5Vq1YhHA5nXm1tbYUuiYiIxkFOQyoYDAIAQqFQ1vZQKJTZFwwG0dnZmbU/nU6ju7s7c8yH6boOr9eb9SIiotKX05BqaGhAMBhES0tLZlskEsGmTZvQ1NQEAGhqakJvby+2bt2aOeall16CaZqYP39+LsshIqIip430Df39/di7d2/m5/3792P79u2oqKhAfX09li9fjjvvvBMzZ85EQ0MDVq9ejdra2swIwNmzZ+Piiy/G9ddfj4ceegipVArLli3D1VdffVIj+4iIaOIYcUi9/vrruPDCCzM/r1ixAgCwZMkS/PKXv8Stt96KgYEB3HDDDejt7cX555+PdevWweFwZN7z2GOPYdmyZbjooougKAoWLVqE++67LwfNISKiUjKm56QKhc9JEREVt4I8J0VERJRLDCkiIrIshhQREVkWQ4qIiCyLIUVERJbFkCIiIstiSBERkWUxpIiIyLIYUkREZFkMKSIisiyGFBERWRZDioiILIshRURElsWQIiIiy2JIERGRZTGkiIjIshhSRERkWQwpIiKyLIYUERFZFkOKiIgsiyFFRESWxZAiIiLLYkgREZFlMaSIiMiyGFJERGRZDCkiIrIshhQREVkWQ4qIiCyLIUVERJbFkCIiIstiSBERkWUxpIiIyLIYUkREZFkMKSIisiyGFBERWRZDioiILIshRURElsWQIiIiy2JIERGRZTGkiIjIshhSRERkWQwpIiKyLIYUERFZFkOKiIgsiyFFRESWxZAiIiLLGnFIbdy4EZdddhlqa2shhMDatWsz+1KpFFauXIk5c+bA7XajtrYWX/3qV9He3p51ju7ubixevBherxd+vx/XXXcd+vv7x9wYIiIqLSMOqYGBAZx55pl44IEHPrIvGo1i27ZtWL16NbZt24annnoKu3btwuWXX5513OLFi/H2229j/fr1eP7557Fx40bccMMNo28FERGVJCGllKN+sxB4+umnceWVVw57zJYtWzBv3jwcOHAA9fX12LlzJ0477TRs2bIFjY2NAIB169bhkksuwaFDh1BbW/uJnxuJRODz+XABroAmbKMtn4iICiQtU3gFzyAcDsPr9Q57XN7vSYXDYQgh4Pf7AQCtra3w+/2ZgAKA5uZmKIqCTZs25bscIiIqIlo+Tx6Px7Fy5Upcc801maTs6OhAdXV1dhGahoqKCnR0dAx5nkQigUQikfk5Eonkr2giIrKMvF1JpVIpfOUrX4GUEg8++OCYzrVmzRr4fL7Mq66uLkdVEhGRleUlpD4IqAMHDmD9+vVZ/Y3BYBCdnZ1Zx6fTaXR3dyMYDA55vlWrViEcDmdebW1t+SibiIgsJufdfR8E1J49e/Dyyy+jsrIya39TUxN6e3uxdetWzJ07FwDw0ksvwTRNzJ8/f8hz6roOXddzXSoREVnciEOqv78fe/fuzfy8f/9+bN++HRUVFaipqcGXvvQlbNu2Dc8//zwMw8jcZ6qoqIDdbsfs2bNx8cUX4/rrr8dDDz2EVCqFZcuW4eqrrz6pkX1ERDRxjHgI+iuvvIILL7zwI9uXLFmCf/mXf0FDQ8OQ73v55ZdxwQUXABh8mHfZsmV47rnnoCgKFi1ahPvuuw8ej+ekauAQdCKi4nayQ9DH9JxUoTCkiIiKm2WekyIiIhothhQREVkWQ4qIiCyLIUVERJbFkCIiIstiSBERkWUxpIiIyLIYUkREZFkMKSIisiyGFBERWRZDioiILIshRURElsWQIiIiy2JIERGRZeV8Zd7x8MHqImmkgKJbaISIiNJIAfjL9/lwijKk+vr6AACv4vcFroSIiMair68PPp9v2P1FueihaZpob2+HlBL19fVoa2v72EWzilkkEkFdXV1JtxFgO0vNRGjnRGgjkL92SinR19eH2tpaKMrwd56K8kpKURRMmTIFkUgEAOD1ekv6lwSYGG0E2M5SMxHaORHaCOSnnR93BfUBDpwgIiLLYkgREZFlFXVI6bqOO+64A7quF7qUvJkIbQTYzlIzEdo5EdoIFL6dRTlwgoiIJoaivpIiIqLSxpAiIiLLYkgREZFlMaSIiMiyijakHnjgAUybNg0OhwPz58/H5s2bC13SmKxZswbnnHMOysrKUF1djSuvvBK7du3KOiYej2Pp0qWorKyEx+PBokWLEAqFClTx2N19990QQmD58uWZbaXSxsOHD+Pv/u7vUFlZCafTiTlz5uD111/P7JdS4vbbb0dNTQ2cTieam5uxZ8+eAlY8coZhYPXq1WhoaIDT6cQpp5yCH/7wh1lzsRVjOzdu3IjLLrsMtbW1EEJg7dq1WftPpk3d3d1YvHgxvF4v/H4/rrvuOvT3949jKz7ex7UxlUph5cqVmDNnDtxuN2pra/HVr34V7e3tWecYtzbKIvTEE09Iu90u/+u//ku+/fbb8vrrr5d+v1+GQqFClzZqCxculI888ojcsWOH3L59u7zkkktkfX297O/vzxzzjW98Q9bV1cmWlhb5+uuvy3PPPVeed955Bax69DZv3iynTZsmP/3pT8ubb745s70U2tjd3S2nTp0qv/a1r8lNmzbJffv2yRdffFHu3bs3c8zdd98tfT6fXLt2rXzzzTfl5ZdfLhsaGmQsFitg5SNz1113ycrKSvn888/L/fv3yyeffFJ6PB757//+75ljirGdv//97+V3v/td+dRTT0kA8umnn87afzJtuvjii+WZZ54pX3vtNfnHP/5RzpgxQ15zzTXj3JLhfVwbe3t7ZXNzs/ztb38r3333Xdna2irnzZsn586dm3WO8WpjUYbUvHnz5NKlSzM/G4Yha2tr5Zo1awpYVW51dnZKAHLDhg1SysFfHJvNJp988snMMTt37pQAZGtra6HKHJW+vj45c+ZMuX79evm5z30uE1Kl0saVK1fK888/f9j9pmnKYDAo//Vf/zWzrbe3V+q6Ln/zm9+MR4k5cemll8qvf/3rWduuuuoquXjxYillabTzw1/gJ9Omd955RwKQW7ZsyRzzwgsvSCGEPHz48LjVfrKGCuIP27x5swQgDxw4IKUc3zYWXXdfMpnE1q1b0dzcnNmmKAqam5vR2tpawMpyKxwOAwAqKioAAFu3bkUqlcpq96xZs1BfX1907V66dCkuvfTSrLYApdPGZ599Fo2Njfjyl7+M6upqnH322fjFL36R2b9//350dHRktdPn82H+/PlF1c7zzjsPLS0t2L17NwDgzTffxKuvvoovfOELAEqnnSc6mTa1trbC7/ejsbExc0xzczMURcGmTZvGveZcCIfDEELA7/cDGN82Ft0Es0ePHoVhGAgEAlnbA4EA3n333QJVlVumaWL58uVYsGABzjjjDABAR0cH7HZ75pfkA4FAAB0dHQWocnSeeOIJbNu2DVu2bPnIvlJp4759+/Dggw9ixYoV+Od//mds2bIF3/rWt2C327FkyZJMW4b6HS6mdt52222IRCKYNWsWVFWFYRi46667sHjxYgAomXae6GTa1NHRgerq6qz9mqahoqKiKNsdj8excuVKXHPNNZkJZsezjUUXUhPB0qVLsWPHDrz66quFLiWn2tracPPNN2P9+vVwOByFLidvTNNEY2MjfvSjHwEAzj77bOzYsQMPPfQQlixZUuDqcud3v/sdHnvsMTz++OM4/fTTsX37dixfvhy1tbUl1c6JLJVK4Stf+QqklHjwwQcLUkPRdfdVVVVBVdWPjPgKhUIIBoMFqip3li1bhueffx4vv/wypkyZktkeDAaRTCbR29ubdXwxtXvr1q3o7OzEZz7zGWiaBk3TsGHDBtx3333QNA2BQKDo2wgANTU1OO2007K2zZ49GwcPHgSATFuK/Xf4O9/5Dm677TZcffXVmDNnDv7+7/8et9xyC9asWQOgdNp5opNpUzAYRGdnZ9b+dDqN7u7uomr3BwF14MABrF+/PmuZjvFsY9GFlN1ux9y5c9HS0pLZZpomWlpa0NTUVMDKxkZKiWXLluHpp5/GSy+9hIaGhqz9c+fOhc1my2r3rl27cPDgwaJp90UXXYS33noL27dvz7waGxuxePHizP8v9jYCwIIFCz7y+MDu3bsxdepUAEBDQwOCwWBWOyORCDZt2lRU7YxGox9ZrE5VVZimCaB02nmik2lTU1MTent7sXXr1swxL730EkzTxPz588e95tH4IKD27NmDP/zhD6isrMzaP65tzOkwjHHyxBNPSF3X5S9/+Uv5zjvvyBtuuEH6/X7Z0dFR6NJG7Zvf/Kb0+XzylVdekUeOHMm8otFo5phvfOMbsr6+Xr700kvy9ddfl01NTbKpqamAVY/diaP7pCyNNm7evFlqmibvuusuuWfPHvnYY49Jl8slf/3rX2eOufvuu6Xf75fPPPOM/POf/yyvuOIKyw/N/rAlS5bIyZMnZ4agP/XUU7KqqkreeuutmWOKsZ19fX3yjTfekG+88YYEIH/yk5/IN954IzOy7WTadPHFF8uzzz5bbtq0Sb766qty5syZlhqC/nFtTCaT8vLLL5dTpkyR27dvz/o+SiQSmXOMVxuLMqSklPL++++X9fX10m63y3nz5snXXnut0CWNCYAhX4888kjmmFgsJm+88UZZXl4uXS6X/Ou//mt55MiRwhWdAx8OqVJp43PPPSfPOOMMqeu6nDVrlnz44Yez9pumKVevXi0DgYDUdV1edNFFcteuXQWqdnQikYi8+eabZX19vXQ4HHL69Onyu9/9btYXWTG28+WXXx7yv8UlS5ZIKU+uTceOHZPXXHON9Hg80uv1ymuvvVb29fUVoDVD+7g27t+/f9jvo5dffjlzjvFqI5fqICIiyyq6e1JERDRxMKSIiMiyGFJERGRZDCkiIrIshhQREVkWQ4qIiCyLIUVERJbFkCIiIstiSBERkWUxpIiIyLIYUkREZFkMKSIisqz/D2WmFfQZ3jphAAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"code","source":"class SlotAttention(nn.Module):\n    def __init__(self, k, d_common=64, n_iter_train=3,n_iter_test=5, d_slot=64, d_inputs=64, hid_dim=128):\n        super(SlotAttention, self).__init__()\n        self.k = k\n        self.d_common = d_common\n        self.n_iter_train = n_iter_train\n        self.n_iter_test = n_iter_test\n        self.d_slot = d_slot\n        self.d_inputs = d_inputs\n\n        self.fc_q = nn.Linear(d_slot, d_common)\n        self.fc_k = nn.Linear(d_inputs, d_common)\n        self.fc_v = nn.Linear(d_inputs, d_common)\n\n        self.gru = nn.GRUCell(d_common, d_slot)\n        self.mlp = nn.Sequential(\n            nn.Linear(d_slot, hid_dim),\n            nn.ReLU(),\n            nn.Linear(hid_dim, d_slot)\n        )\n\n        self.softmax = nn.Softmax(dim=2)\n        self.mu = nn.Parameter(torch.randn(1, 1,d_common))\n        self.sigma = nn.Parameter(torch.rand(1,1, d_common))\n\n    \n    def forward(self, inputs):\n        # inputs: (batch_size, n_inputs, d_inputs)\n        # slots: (batch_size, n_slots, d_slot)\n        if self.training:\n            n_iter = self.n_iter_train\n        else:\n            n_iter = self.n_iter_test\n        batch_size, n_inputs, d_inputs = inputs.size()\n        mu = self.mu.expand(batch_size, self.k, -1)\n        sigma = self.sigma.expand(batch_size, self.k, -1)\n        slots = torch.normal(mu, sigma).to(device)\n        inputs = nn.LayerNorm(d_inputs).to(device)(inputs)\n        k = self.fc_k(inputs)               # (batch_size, n_inputs, d_common)\n        v = self.fc_v(inputs)               # (batch_size, n_inputs, d_common)\n        for i in range(n_iter):\n            q = self.fc_q(nn.LayerNorm(self.d_slot).to(device)(slots))                # (batch_size, n_slots, d_common)\n\n            attn = torch.bmm(k, q.permute(0, 2, 1)) / np.sqrt(self.d_common)            # (batch_size, n_inputs, n_slots)\n            attn = self.softmax(attn) +  1e-8                                           # (batch_size, n_inputs, n_slots)\n            attn = attn / attn.sum(dim=1, keepdim=True)                                 # (batch_size, n_inputs, n_slots)\n            attn = attn.permute(0,2,1)\n            updates = torch.einsum('bjd,bij->bid', v, attn)                             # (batch_size, n_slots, d_common)\n\n\n            slots = self.gru(updates.reshape(-1,self.d_common), slots.reshape(-1, self.d_slot)).reshape(batch_size, self.k, self.d_slot)\n            slots = nn.LayerNorm(self.d_slot).to(device)(slots)\n            slots = slots + self.mlp(slots)\n        \n        return slots\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-07T14:23:22.899219Z","iopub.execute_input":"2024-05-07T14:23:22.899955Z","iopub.status.idle":"2024-05-07T14:23:22.915599Z","shell.execute_reply.started":"2024-05-07T14:23:22.899926Z","shell.execute_reply":"2024-05-07T14:23:22.914337Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class PositionalEmbeddings(nn.Module):\n    def __init__(self, H, W, hid_dim=64):\n        super(PositionalEmbeddings, self).__init__()\n        self.H = H\n        self.W = W\n        self.hid_dim = hid_dim\n        self.project = nn.Linear(4, hid_dim)\n    \n    def construct_grid(self, H, W):\n        x = torch.linspace(0, 1, W).unsqueeze(0).repeat(H, 1)\n        y = torch.linspace(0, 1, H).unsqueeze(1).repeat(1, W)\n        return torch.stack([x, 1-x, y, 1-y], dim=2)    # (H, W, 4)\n\n\n    def forward(self, inputs):\n        grid = self.construct_grid(self.H, self.W).to(device)  # (H, W, 4)\n        grid = self.project(grid)\n        return inputs + grid.unsqueeze(0).expand(inputs.size(0), self.H, self.W, self.hid_dim)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T14:23:23.296528Z","iopub.execute_input":"2024-05-07T14:23:23.296952Z","iopub.status.idle":"2024-05-07T14:23:23.306564Z","shell.execute_reply.started":"2024-05-07T14:23:23.296923Z","shell.execute_reply":"2024-05-07T14:23:23.305238Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class CNNEncoder(nn.Module):\n    def __init__(self, hid_dim=64):\n        super(CNNEncoder, self).__init__()\n        self.conv1 = nn.Conv2d(3, hid_dim, 5, padding=2)                    \n        self.conv2 = nn.Conv2d(hid_dim, hid_dim, 5, padding=2)\n        self.conv3 = nn.Conv2d(hid_dim, hid_dim, 5, padding=2)\n        self.conv4 = nn.Conv2d(hid_dim, hid_dim, 5, padding=2)\n\n        self.positionalEmb = PositionalEmbeddings(128, 128, hid_dim)\n        self.relu = nn.ReLU()\n\n        self.fc1 = nn.Linear(hid_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, hid_dim)  \n\n\n    def forward(self, inputs):\n        inputs = self.conv1(inputs)\n        inputs = self.relu(inputs)\n        inputs = self.conv2(inputs)\n        inputs = self.relu(inputs)\n        inputs = self.conv3(inputs)\n        inputs = self.relu(inputs)\n        inputs = self.conv4(inputs)\n        inputs = self.relu(inputs)\n        \n        inputs = self.positionalEmb(inputs.permute(0, 2, 3, 1))\n        inputs = inputs.flatten(1, 2)\n        inputs = nn.LayerNorm(inputs.size()[1:]).to(device)(inputs) \n        inputs = self.fc1(inputs)\n        inputs = self.relu(inputs)\n        inputs = self.fc2(inputs)\n        return inputs\n           ","metadata":{"execution":{"iopub.status.busy":"2024-05-07T14:23:23.710684Z","iopub.execute_input":"2024-05-07T14:23:23.711088Z","iopub.status.idle":"2024-05-07T14:23:23.722196Z","shell.execute_reply.started":"2024-05-07T14:23:23.711059Z","shell.execute_reply":"2024-05-07T14:23:23.720879Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class deconvDecoder(nn.Module):\n    def __init__(self, hid_dim=64):\n        super(deconvDecoder, self).__init__()\n        self.hid_dim = hid_dim\n        self.deconv1 = nn.ConvTranspose2d(hid_dim, hid_dim, 5, padding=2, output_padding=1, stride=2)\n        self.deconv2 = nn.ConvTranspose2d(hid_dim, hid_dim, 5, padding=2, output_padding=1, stride=2)\n        self.deconv3 = nn.ConvTranspose2d(hid_dim, hid_dim, 5, padding=2, output_padding=1, stride=2)\n        self.deconv4 = nn.ConvTranspose2d(hid_dim, hid_dim, 5, padding=2, output_padding=1, stride=2)\n        self.deconv5 = nn.ConvTranspose2d(hid_dim, hid_dim, 5, padding=2, output_padding=0, stride=1)\n        self.deconv6 = nn.ConvTranspose2d(hid_dim, 4, 3, padding=1, output_padding=0, stride=1)\n\n        self.relu = nn.ReLU()\n        self.positionalEmb = PositionalEmbeddings(8, 8, hid_dim)\n\n    def forward(self, slots):\n        # slots: (batch_size, n_slots, d_slot)\n        b, k, d = slots.size()\n        slots = slots.unsqueeze(2).unsqueeze(3).expand(b, k, 8, 8, d)\n        slots = slots.reshape(b*k, 8, 8, d)\n        slots = self.positionalEmb(slots)\n        slots = slots.permute(0, 3, 1, 2)\n        slots = self.deconv1(slots)\n        slots = self.relu(slots)\n        slots = self.deconv2(slots)\n        slots = self.relu(slots)\n        slots = self.deconv3(slots)\n        slots = self.relu(slots)\n        slots = self.deconv4(slots)\n        slots = self.relu(slots)\n        slots = self.deconv5(slots)\n        slots = self.relu(slots)\n        slots = self.deconv6(slots)                 # (batch_size * n_slots, 4, 128, 128)\n\n        slots = slots.reshape(b, k, 4, 128, 128)\n        slots = slots.permute(0, 1, 3, 4, 2)\n        contents, masks = slots.split([3, 1], dim=4)        # (batch_size, n_slots, 128, 128, 3)\n        masks = nn.Softmax(dim=1)(masks)                    # (batch_size, n_slots, 128, 128, 1)\n        img = (contents * masks).sum(dim=1)\n        img = img.permute(0, 3, 1, 2)\n\n        return img, masks\n    \n    def get_slot_imgs(self, slots, name):\n        b, k, d = slots.size()\n        slots = slots.unsqueeze(2).unsqueeze(3).expand(b, k, 8, 8, d)\n        slots = slots.reshape(b*k, 8, 8, d)\n        slots = self.positionalEmb(slots)\n        slots = slots.permute(0, 3, 1, 2)\n        slots = self.deconv1(slots)\n        slots = self.relu(slots)\n        slots = self.deconv2(slots)\n        slots = self.relu(slots)\n        slots = self.deconv3(slots)\n        slots = self.relu(slots)\n        slots = self.deconv4(slots)\n        slots = self.relu(slots)\n        slots = self.deconv5(slots)\n        slots = self.relu(slots)\n        slots = self.deconv6(slots)                 # (batch_size * n_slots, 4, 128, 128)\n\n        slots = slots.reshape(b, k, 4, 128, 128)\n        slots = slots.permute(0, 1, 3, 4, 2)\n        contents, masks = slots.split([3, 1], dim=4)        # (batch_size, n_slots, 128, 128, 3)\n        masks = nn.Softmax(dim=1)(masks)                    # (batch_size, n_slots, 128, 128, 1)\n        img = torch.tensor((contents * masks) * 255, dtype=torch.uint8).cpu().numpy()\n        img_dir = 'img_dir/'\n        if(not os.path.exists(out_dir + img_dir)):\n            os.makedirs(out_dir + img_dir)\n        img_recon = torch.tensor(((contents * masks).sum(dim=1) * 255), dtype=torch.uint8).cpu().numpy()\n        for i in range(b):\n#             for j in range(k):\n#                 img_name = name + '_slot' + str(j) + '_img' + str(i) + '.png'\n#                 plt.imsave(out_dir + img_dir + img_name, img[i,j])\n            plt.imsave(out_dir + img_dir + name + '_img' + str(i) + '_reconstructed.png', img_recon[i])\n        \n\n\n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-07T14:23:24.124016Z","iopub.execute_input":"2024-05-07T14:23:24.124403Z","iopub.status.idle":"2024-05-07T14:23:24.147523Z","shell.execute_reply.started":"2024-05-07T14:23:24.124374Z","shell.execute_reply":"2024-05-07T14:23:24.146348Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class SlotAttentionModel(nn.Module):\n    def __init__(self, k, d_common=64, n_iter_train=3, n_iter_test=5, d_slot=64, d_inputs=64, hid_dim=64):\n        super(SlotAttentionModel, self).__init__()\n        self.encoder = CNNEncoder(hid_dim)\n        self.slotAttention = SlotAttention(k, d_common, n_iter_train, n_iter_test, d_slot, d_inputs, hid_dim)\n        self.decoder = deconvDecoder(hid_dim)\n    \n    def forward(self, inputs):\n        features = self.encoder(inputs)\n        slots = self.slotAttention(features)\n        img, masks = self.decoder(slots)\n        return img, masks\n    \n    def get_slot_imgs(self, inputs, name):\n        features = self.encoder(inputs)\n        slots = self.slotAttention(features)\n        self.decoder.get_slot_imgs(slots, name)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T14:26:37.671373Z","iopub.execute_input":"2024-05-07T14:26:37.672111Z","iopub.status.idle":"2024-05-07T14:26:37.680187Z","shell.execute_reply.started":"2024-05-07T14:26:37.672079Z","shell.execute_reply":"2024-05-07T14:26:37.679064Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# load_model = True\n# SAM = SlotAttentionModel(11, 64, 3, 5, 64, 64, 64)\n# SAM = nn.DataParallel(SAM)\n# SAM.to(device)\n# if load_model:\n#     SAM.load_state_dict(torch.load('/kaggle/input/modelv1/pytorch/v2/1/modelv1.pth'))\n# criterion = nn.MSELoss()\n# init_lr = 0.0004\n# optimizer = optim.Adam(SAM.parameters(), lr=init_lr)\n\n\n# warmup_iters = 10000\n# decay_steps = 100000\n# decay_rate = 0.5\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjusted_rand_index(true_ids, pred_ids):\n    \"\"\"\n    Args:\n        true_masks: Integer ids for objects\n            [batch_size, H, W].  \n            as integer ids.\n        pred_masks: An integer-valued array of shape\n            [batch_size, K, H, W]. The predicted cluster assignment\n            encoded as integer ids.\n        ignore_background: Boolean, if True, then ignore all pixels where\n            true_ids == 0 (default: False).\n\n    Returns:\n        ARI scores as a float32 array of shape [batch_size].\n    \"\"\"\n    pred_ids = pred_ids.argmax(dim=-3)  # [B, N, H, W] --> [B, H, W]\n\n    if len(true_ids.shape) == 3:\n        true_ids = true_ids.unsqueeze(1)\n    if len(pred_ids.shape) == 3:\n        pred_ids = pred_ids.unsqueeze(1)\n    true_oh = F.one_hot(true_ids).float()\n    pred_oh = F.one_hot(pred_ids).float()\n    N = torch.einsum(\"bthwc,bthwk->bck\", true_oh, pred_oh)\n    A = torch.sum(N, dim=-1)  # row-sum  (batch_size, c)\n    B = torch.sum(N, dim=-2)  # col-sum  (batch_size, k)\n    num_points = torch.sum(A, dim=1)\n\n    rindex = torch.sum(N * (N - 1), dim=[1, 2])\n    aindex = torch.sum(A * (A - 1), dim=1)\n    bindex = torch.sum(B * (B - 1), dim=1)\n    expected_rindex = aindex * bindex / torch.clamp(\n        num_points * (num_points - 1), min=1)\n    max_rindex = (aindex + bindex) / 2\n    denominator = max_rindex - expected_rindex\n    ari = (rindex - expected_rindex) / denominator\n\n    # There are two cases for which the denominator can be zero:\n    # 1. If both label_pred and label_true assign all pixels to a single cluster.\n    #    (max_rindex == expected_rindex == rindex == num_points * (num_points-1))\n    # 2. If both label_pred and label_true assign max 1 point to each cluster.\n    #    (max_rindex == expected_rindex == rindex == 0)\n    # In both cases, we want the ARI score to be 1.0:\n    return torch.where(denominator != 0, ari, torch.tensor(1.).type_as(ari))","metadata":{"execution":{"iopub.status.busy":"2024-05-07T15:31:38.227413Z","iopub.execute_input":"2024-05-07T15:31:38.227951Z","iopub.status.idle":"2024-05-07T15:31:38.241190Z","shell.execute_reply.started":"2024-05-07T15:31:38.227912Z","shell.execute_reply":"2024-05-07T15:31:38.240145Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"# torch.autograd.set_detect_anomaly(True)\n# def train(model, criterion, optimizer, train_loader, num_epochs):\n#     counter = 21700*2\n#     for epoch in range(num_epochs):\n#         model.train()\n#         running_loss = 0.0\n#         for i, (images) in enumerate(train_loader):\n#             counter += 1\n#             images = images.to(device)\n#             if counter < warmup_iters:\n#                 learning_rate = init_lr*(counter/warmup_iters)\n#             else:\n#                 learning_rate = init_lr\n#             learning_rate = learning_rate * (decay_rate ** (counter/decay_steps))\n#             optimizer.param_groups[0]['lr'] = learning_rate\n#             optimizer.zero_grad()\n#             outputs = model(images)\n#             loss = criterion(outputs, images)\n#             loss.backward()\n#             optimizer.step()\n#             running_loss += loss.item()\n#             if i % 10 == 9:\n#                 print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n#                 running_loss = 0.0\n#             del images, outputs, loss\n#         torch.save(model.state_dict(), 'modelv2.pth')\n#     print('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2024-05-07T14:32:59.045100Z","iopub.execute_input":"2024-05-07T14:32:59.045912Z","iopub.status.idle":"2024-05-07T14:32:59.051372Z","shell.execute_reply.started":"2024-05-07T14:32:59.045879Z","shell.execute_reply":"2024-05-07T14:32:59.050127Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# train(SAM, criterion, optimizer, train_loader, n_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T14:33:00.302405Z","iopub.execute_input":"2024-05-07T14:33:00.302768Z","iopub.status.idle":"2024-05-07T14:33:00.307177Z","shell.execute_reply.started":"2024-05-07T14:33:00.302742Z","shell.execute_reply":"2024-05-07T14:33:00.305920Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"model = SlotAttentionModel(11, 64, 3, 5, 64, 64, 64)\nmodel = nn.DataParallel(model)\nmodel.to(device)\nmodel.load_state_dict(torch.load('/kaggle/input/models-new/modelv2.pth'))","metadata":{"execution":{"iopub.status.busy":"2024-05-07T14:53:41.541084Z","iopub.execute_input":"2024-05-07T14:53:41.541807Z","iopub.status.idle":"2024-05-07T14:53:41.579803Z","shell.execute_reply.started":"2024-05-07T14:53:41.541771Z","shell.execute_reply":"2024-05-07T14:53:41.578875Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"def remove_background(true_masks, pred_masks):\n    mask = (true_masks != 0)\n    true_masks = true_masks[mask]\n    pred_masks = pred_masks[mask]\n    return true_masks, pred_masks","metadata":{"execution":{"iopub.status.busy":"2024-05-07T15:27:43.110063Z","iopub.execute_input":"2024-05-07T15:27:43.110480Z","iopub.status.idle":"2024-05-07T15:27:43.116101Z","shell.execute_reply.started":"2024-05-07T15:27:43.110446Z","shell.execute_reply":"2024-05-07T15:27:43.114898Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"# print(remove_background(torch.tensor([[0,0,0],[1,1,0],[1,0,0]]), torch.tensor([[1,1,2],[0,1,1],[3,1,1]])))","metadata":{"execution":{"iopub.status.busy":"2024-05-07T15:19:41.550490Z","iopub.execute_input":"2024-05-07T15:19:41.551175Z","iopub.status.idle":"2024-05-07T15:19:41.558541Z","shell.execute_reply.started":"2024-05-07T15:19:41.551145Z","shell.execute_reply":"2024-05-07T15:19:41.557531Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"(tensor([1, 1, 1]), tensor([0, 1, 3]))\n","output_type":"stream"}]},{"cell_type":"code","source":"# adjusted_rand_score(torch.tensor([1,2,2,2,2,4]), torch.tensor([1,4,3,3,3,2]))","metadata":{"execution":{"iopub.status.busy":"2024-05-07T15:21:33.461130Z","iopub.execute_input":"2024-05-07T15:21:33.461514Z","iopub.status.idle":"2024-05-07T15:21:33.470677Z","shell.execute_reply.started":"2024-05-07T15:21:33.461486Z","shell.execute_reply":"2024-05-07T15:21:33.469748Z"},"trusted":true},"execution_count":105,"outputs":[{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"0.5454545454545454"},"metadata":{}}]},{"cell_type":"code","source":"def calc_ARI(model, data_loader):\n    model.eval()\n    ARI = 0\n    with torch.no_grad():\n        for i, (images, true_masks) in enumerate(data_loader):\n            print(i, end='\\r')\n            images = images.to(device)\n            true_masks = true_masks.to(device)\n            outputs, pred_masks = model(images)\n            if ARI == 0:\n                ARI = adjusted_rand_index(true_masks.long().cpu(), pred_masks.squeeze(-1).cpu())\n            else:\n                ARI += adjusted_rand_index(true_masks.long().cpu(), pred_masks.squeeze(-1).cpu())\n#             pred_masks = torch.argmax(pred_masks.squeeze(-1), dim=1)\n#             true_masks, pred_masks = remove_background(true_masks, pred_masks)\n#             if i == 0:\n#                 print(true_masks.shape, pred_masks.shape)\n#             if ARI == 0:\n#                 ARI = adjusted_rand_index(true_masks.long().cpu(), pred_masks.cpu())\n#             else:\n#                 ARI += adjusted_rand_index(true_masks.long().cpu(), pred_masks.cpu())\n            del images, true_masks, outputs, pred_masks\n    return ARI / len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T15:31:40.941163Z","iopub.execute_input":"2024-05-07T15:31:40.941871Z","iopub.status.idle":"2024-05-07T15:31:40.950736Z","shell.execute_reply.started":"2024-05-07T15:31:40.941834Z","shell.execute_reply":"2024-05-07T15:31:40.949685Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"print(calc_ARI(model, val_loader))","metadata":{"execution":{"iopub.status.busy":"2024-05-07T15:31:41.298630Z","iopub.execute_input":"2024-05-07T15:31:41.299372Z","iopub.status.idle":"2024-05-07T15:37:39.691336Z","shell.execute_reply.started":"2024-05-07T15:31:41.299339Z","shell.execute_reply":"2024-05-07T15:37:39.690375Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"tensor([0.5439])\n","output_type":"stream"}]},{"cell_type":"code","source":"def K_mean(trained_model, data_loader, k):\n    trained_model.eval()\n    slots = []\n    with torch.no_grad():\n        for i, (images) in enumerate(data_loader):\n            images = images.to(device)\n            features = trained_model.module.encoder(images)\n            slots.append(trained_model.module.slotAttention(features))\n        slots = torch.cat(slots, dim=0)         # (n_samples, n_slots, d_slot)\n        slots = slots.reshape(-1, slots.size(2))\n        kmeans = KMeans(n_clusters=k).fit(slots.cpu().detach().numpy())\n    return kmeans, slots\n\ndef get_slot_imgs(trained_model, kmeans, slots,  nval):\n    trained_model.eval()\n    samples = nval\n    labels = torch.tensor(kmeans.labels_).flatten()\n    for i in range(samples):\n        print(i)\n        sampled_slots = [0,0,0,0,0,0,0,0,0,0,0]\n        for j in range(11):\n            possible_slots = np.where(labels == j)[0]\n            idx = np.random.choice(possible_slots)\n            sampled_slots[j] = slots[idx]\n        sampled_slots = torch.stack(sampled_slots, dim=0)\n        sampled_slots = sampled_slots.unsqueeze(0)\n        print(sampled_slots.shape)\n        with torch.no_grad():\n            trained_model.module.decoder.get_slot_imgs(sampled_slots, 'sample' + str(i))","metadata":{"execution":{"iopub.status.busy":"2024-05-07T14:56:11.843215Z","iopub.execute_input":"2024-05-07T14:56:11.844084Z","iopub.status.idle":"2024-05-07T14:56:11.854071Z","shell.execute_reply.started":"2024-05-07T14:56:11.844052Z","shell.execute_reply":"2024-05-07T14:56:11.853106Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"kmeans = K_mean(model, train_loader, 11)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_slot_imgs(model, kmeans[0], kmeans[1], 10000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from matplotlib import pyplot as plt\n# def pred(model, loader, num):\n#     model.eval()\n#     n = 0\n#     for i, (images) in enumerate(loader):\n#         n+=1\n#         images = images.to(device)\n#         outputs = model(images)\n#         outputs = outputs.detach().cpu().numpy()\n#         outputs = outputs * 255\n#         outputs = outputs.astype(np.uint8)\n#         images = images.detach().cpu().numpy()\n#         images = images * 255\n#         images = images.astype(np.uint8)\n\n#         # save output images and images\n#         for j in range(images.shape[0]):\n#             plt.imsave(out_dir + 'reconstructed.png', outputs[j].transpose(1, 2, 0))\n#             plt.imsave(out_dir + 'original.png', images[j].transpose(1, 2, 0))\n#             n += 1\n#             if n == num:\n#                 break\n            \n#         if n == num:\n#             break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred(model, train_loader, 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred(model, loader):\n    model.eval()\n    for i, (images) in enumerate(loader):\n        images = images.to(device)\n        model(images,\"f\")\n        images = images.detach().cpu().numpy()\n        images = images * 255\n        images = images.astype(np.uint8)\n        for b in range(images.shape[0]):\n            plt.imsave(out_dir + 'img_dir/img' + str(b) + '_orig.png', images[b].transpose(1,2,0))\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred(model, train_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.make_archive('img_dir_zipped', 'zip', '/kaggle/working/img_dir')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}